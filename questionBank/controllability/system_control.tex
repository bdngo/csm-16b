% Author: Taejin Hwang
% Email: taejin@berkeley.edu

\qns{Controlling a System}

We are given a discrete time state space system, where $\vec{x}$ is our \textbf{state vector}, $A$ is the \textbf{state space model} of the system, $B$ is the \textbf{input matrix}, and $\vec{u}$ is the \textbf{control input vector}.
\begin{equation}
\vec{x}[t + 1] = A \vec{x}[t] + B\vec{u}[t]
\end{equation}
We define a system to be controllable if: \textbf{given a set of inputs, we can move the system from any initial state to any final state by choosing a sequence of inputs.} This has an important physical meaning; if a physical system is controllable, that means that we can get anywhere in the state space. For example, if a robot is controllable, it is able to travel anywhere in the system it is living in (given enough time and control inputs).

\textbf{We will start with the assumption that the system started at rest at the zero vector: $\vec{x}[0] = \vec{0}$}, and our state space will be an n-dimensional vector in $\mathbb{R}^{n}.$ 

\begin{enumerate}

\qitem \textbf{How can you write out $\vec{x}[1]$ using the state space equation? How about $\vec{x}[2]?$}

\ws{\vspace{75px}}
\sol {
  Using the state space model $\vec{x}[i + 1] = A \vec{x}[i] + B \vec{u}[i],$
  $$\vec{x}[1] = A \vec{x}[0] + B \vec{u}[0] = A \vec{0} + B \vec{u}[0] = B \vec{u}[0]$$
  At time step $t = 2,$
  $$\vec{x}[2] = A \vec{x}[1] + B \vec{u}[1] = A (B \vec{u}[0]) + B \vec{u}[1]$$
}

\qitem \textbf{Given these two observations and the initial condition $\vec{x}[0] = \vec{0}$, where can $\vec{x}$ reach in our state space reach after 2 time steps (i.e. at $t = 2$)?}
\ws{\vspace{100px}}
\sol {
  From the previous part, we know that
  $$\vec{x}[2] = A (B \vec{u}[0]) + B \vec{u}[1] = AB \vec{u}[0] + B \vec{u}[1]$$
  Let's say $B$ has two columns, although we can generalize this for any number of columns. \vskip 1pt
  We can then equivalently write out our equation as:
  $$\vec{x}[2] = \begin{bmatrix} A \vec{b}_{1} & A \vec{b}_{2} \end{bmatrix} \begin{bmatrix} u_{1}[0] \\ u_{2}[0] \end{bmatrix} + 
  \begin{bmatrix} \vec{b}_{1} & \vec{b}_{2} \end{bmatrix} \begin{bmatrix} u_{1}[1] \\ u_{2}[1] \end{bmatrix} = 
  u_{1}[0] A \vec{b}_{1} + u_{2}[0] A \vec{b}_{2} + u_{1}[1] \vec{b}_{1} + u_{2}[1] \vec{b}_{2}.$$
  Since $\vec{u}$ is a vector we have full control over, we can reach anywhere in:
  $$\text{span}(A \vec{b}_{1}, A \vec{b}_{2}, \vec{b}_{1}, \vec{b}_{2})$$
  In general, we could reach anywhere in the span of the columns of $B$ and $AB.$
}

\qitem \textbf{Given $n$ observations, where in our state space can $\vec{x}$ reach at time $t = n?$}
\ws{\vspace{100px}}
\sol {
  We will start off in a similar manner by writing out $\vec{x}(3)$ in terms of $\vec{x}[2]$ and $\vec{u}[2].$
  $$\vec{x}(3) = A \vec{x}[2] + B \vec{u}[2] =  A (AB \vec{u}[0] + B \vec{u}[1]) + B \vec{u}[2] = A^2 B \vec{u}[0] + AB \vec{u}[1] + B \vec{u}[2].$$
  Using a similar argument as the previous part, we will see that we can reach anywhere in the span of the columns of $B, \ AB, \ A^{2} B.$ We can continue doing this, and see that after $n$ time steps,
  \begin{align*}
  \vec{x}[i] &= A \vec{x}[i - 1] + B \vec{u}[i - 1] \\
  &= A^{n - 1}B \vec{u}[0] + A^{n - 2}B \vec{u}[1] + A^{n - 3}B \vec{u}[2] + \cdots + AB \vec{u}[i - 2] + B \vec{u}[i - 1]
  \end{align*}
  Therefore, after $n$ timesteps, we can reach anywhere in the span of the columns of $\{ B, \ AB, \ A^2 B, \cdots, A^{n-1} B \}.$
}

\qitem \textbf{Show that if the columns of $A^{k} B$ are linearly dependent, then the columns of $A^{k + 1} B$ are also linearly dependent.}
\ws{\vspace{100px}}
\meta {
  Make sure your students understand the reason for proving this. We want to be able to define a \textit{finite} controllability matrix to check if a system is controllable. If we don't prove that we only need to check up to $A^{n - 1}B$, then there's no guarantee that some infinitely large controllability matrix may end up having rank $n$.
}
\sol {
  We first make the observation that the columns of $A^{k} B$ are:
  $$A^{k} B = \begin{bmatrix} A^{k} \vec{b_1} & A^{k} \vec{b_2} & \cdots & A^{k} \vec{b_m} \end{bmatrix}$$
  Where $\vec{b}_{i}$ is the $i^{th}$ column of the matrix $B.$ \vskip 1pt
  Now let's suppose that the columns of $A^{k} B$ are linearly dependent. 
  We can say that if we have scalars $\alpha_i$ such that 
  $$\alpha_{1} A^{k} \vec{b_1} + \cdots + \alpha_{m} A^{k} \vec{b_m} = \vec{0},$$
  then at least one of the $\alpha_i$ must be nonzero. Now if we left multiply by $A,$ we see that:
  $$A(\alpha_{1} A^{k} \vec{b_1} + \cdots + \alpha_{m} A^{k} \vec{b_m}) = \alpha_{1} A^{k+1} \vec{b_1} + \cdots + \alpha_{m} A^{k+1} \vec{b_m} = \vec{0}.$$ 
  As a result, we observe that if we have a linear combination of the columns of $A^{k + 1} B$ equal to the zero vector, at least one of the scalars is nonzero. This shows that the columns of $A^{k + 1} B$ must be linearly dependent.
}

\qitem To summarize our work from the previous parts, we now define a controllability matrix

\meta {
  This is definitely the most difficult part of the question. 
  The previous parts were more or less intuitive, but here students will have to think about how part (d) relates to "redundant" measurements.
}

\begin{equation}
\mathcal{C} = \begin{bmatrix} B & AB & A^2B & \cdots & A^{n-2}B & A^{n-1}B \end{bmatrix}
\end{equation}
\textbf{Based on the previous parts, when can we say our system is controllable? (i.e. we can reach anywhere in our state space using our system)}

\sol {
  Using our knowledge from part (c), we can say that $\vec{x}$ can reach anywhere in the span of the columns of $\mathcal{C}$ after $n$ time steps. 
  We also saw in part (d), that if $A^{k}B$ had linearly dependent columns, then $A^{k + 1}B$ will also have linearly dependent columns. \vskip 1pt
  This means if one of our measurements at time $t = k,$ was linearly dependent from our previous measurements, then the future measurements $t = k + 1$ onward, will also be linearly dependent from the previous ones. In other words, every redundant measurement taken after a redundant one will continue to be redundant. \vskip 1pt
  We must take at least $n$ measurements, since we want to span all of $\mathbb{R}^n,$ and $B$ may just be a single vector.
  Therefore, we conclude by saying that our system can reach anywhere in our state-space, $\mathbb{R}^{n},$ if $\mathcal{C}$ is a matrix of rank $n.$ \vskip 1pt
  This does not mean that $\mathcal{C}$ has to be invertible, it just means that $\mathcal{C}$ must have $n$ linearly independent columns for the system to be controllable.
}

\end{enumerate}